{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e86bb9",
   "metadata": {},
   "source": [
    "# Deep Learning - Lecture 1\n",
    "## Introduzione\n",
    "Nel 50 primo paper sul turing test -> inizio AI\n",
    "Perceptron, primi neuroni. Epoca teorica.\n",
    "\n",
    "Negli anni 80 sono arrivati i primi veri computer che potevano essere programmati -> ML\n",
    "\n",
    "Negli anni 10 arrivano le gpu potenti che potevano fare calcoli tensoriali -> DL\n",
    "\n",
    "\n",
    "## Come funziona L'intelligenza artificiale\n",
    "\n",
    "Ci sono due tipi di task:\n",
    "- astratto e formale: facile per pc, difficili per umani. e' un approccio knowledge-based: ex tutte le partite dei migliori giocatori di scacchi le dai in pasto al computer e ottieni un modello che sa massimizzare le sue chance di vittoria etc\n",
    "\n",
    "- catturare il concetto, intuizione: faicile per umani difficile per pc. esempio: riconoscere numeri scritti a mano su carta\n",
    "\n",
    "qualche anno fa prima di DL il primo era l'unico su cui avevamo controllo. adesso riusciamo a gestire anche il secondo\n",
    "\n",
    "Def. Machine Learning (Mitchell 1998): computer impara da esperienza E rispetto a una classe di task T e misure di performance P, SE la performance su T, misurata da P migliora con l'esperienza E.\n",
    "\n",
    "Deep Learning: Modelli più complessi che imparano da soli come estrarre dati utili dall'input grezzo.\n",
    "\n",
    "## ML per la fisica\n",
    "\n",
    "L'LHC e' stato uno dei primi strumenti a usare queste tecniche per scoprire il bosone di higgs: tracking di particelle, simulazione etc...\n",
    "\n",
    "Anche usato in jet simulazione e analisi.\n",
    "\n",
    "## Learning Paradigm\n",
    "\n",
    "Ci sono diversi tipi di algoritmi di machine learning: \n",
    "\n",
    "- Supervised Learning: Confrontiamo l'output di un training dataset con l'output desiderato e verifichiamo che corrispondano -> output.\n",
    " Fare predizioni per nuovi dati osservati\n",
    "\n",
    "- Unsupervised Learning: Non c'e' training dataset, chiedo alla macchina di estrarre labels utili per capire qualcosa di più dai dati (ex modelli generativi)       \n",
    " Estrazione di feature dal dataset.\n",
    "\n",
    "- Reinforcement Learning: Macchina svolge un azione in un environment e riceve reward per le azioni corrette -> massimizzare rewards\n",
    "\n",
    "## Performance del modello in supervised learning\n",
    "\n",
    "Metriche e stimatori statistici per le perfformance del modello ex. Costo / loss / accuracy...\n",
    "\n",
    "Sostanzialmente vogliamo il minimo della funzione di costo $J(w)$ che misura la differenza tra il target e l'output del modello.\n",
    "\n",
    "Uno dei più usati per la regressione e' il Mean Square Error (MSE): $J(w) = \\frac{1}{n} \\sum{(y_i - y_w (x_i))^2}$\n",
    "\n",
    "Ma ce ne sono anche altre tipo il chi quadrato data una matrice di covarianza (in generale non diagonale, se c'e' correlazione tra i dati) e altre\n",
    "\n",
    "## Training e test sets\n",
    "\n",
    "In supervised learning non vogliamo che il modello impari il rumore e vogliamo che generalizzi l'output per nuovi dati.\n",
    "\n",
    "Divido quindi il mio set di dati in training e in test. \n",
    "\n",
    "Dividere il dataset mi darà due metriche di errori: training error, generalization error (overfitting)\n",
    "\n",
    "- Se il modello è molto complesso impara bene i dati di training ma rischia di non generalizzare bene sui dati di test (rischio di overifitting) => alto generalization error\n",
    "- Se il modello è troppo semplice entrambi gli errori divergono a $+\\infty$ (ho underfitting)\n",
    "\n",
    "Trovare il bilanciamento tra questi due errori si chiama bias-variance trade-off.\n",
    "\n",
    "Dato un modello $y(x)$ determinato da un training dataset e considereando un modello ideale (vero) $Y = y(X) + \\epsilon$ ove $y(x) = E(Y|X = x)$\n",
    "\n",
    "Definisco: \n",
    "\n",
    "Bias: $Bias[\\hat{y}(x_0)] = E(\\hat{y}(x_0)) - y(x_0)$\n",
    "\n",
    "Varianza: $Var[\\hat{y}(x_0)] = E(\\hat{y}(x_0)^2) - (E[\\hat{y}(x_0)])^2$\n",
    "\n",
    "Tutto questo e' molto bello ma non e' detto che io abbia una true law. Quindi le tecniche di regolarizzazione si possono appplicare all'algoritmo e ridurre un errore di generalizzazione ma non il training error, evitando grande oscillazioni, numeri grandi etc...\n",
    "\n",
    "Per risolvere questo problema devo introdurre un altro problema, nella forma di iperparametri che fittano più o meno i dati a seconda di come li ho tunati.\n",
    "\n",
    "Ad esempio nella cost function del MSE aggiungo un termine in più (tecnica di weight decay): $J(w) = \\frac{1}{n} \\sum{(y_i - y_w (x_i))^2} + \\lambda \\omega^T\\omega$\n",
    "\n",
    "Per tunare gli iperparametri spesso posso usare un validation set nel dataset iniziale.\n",
    "\n",
    "Piccolo includere anche una metrica di accuratezza oltre alla cost function nei problemi di classificazioni binari in cui ho una matrice di risulati, sulla diagonale quelli giusti, off diagonal quelli sbagliati (false positives / false neg) da questa matrice posso anche estrarre altre metriche come recall e mescolando precision con recall ottengo l'F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4c168",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
